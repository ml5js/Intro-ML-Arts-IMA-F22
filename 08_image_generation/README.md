# Image Generation

## Objectives

- What is foundation model
- What is diffusion model
- Become familiar with Runway and understand how to run new models/tools in the browser.
- Explore DALL-E 2 image generation tool

## Background on RunwayML

- [Machine Learning En Plein Air: Building accessible tools for artists](https://medium.com/runwayml/machine-learning-en-plein-air-building-accessible-tools-for-artists-87bfc7f99f6b) by Cristóbal Valenzuela
- [Runway: Adding artificial intelligence capabilities to design and creative platforms](https://nips2018creativity.github.io/doc/runway.pdf) by Cristóbal Valenzuela, Alejandro Matamala, and Anastasis Germanidis

## Resources

- [Foundation models on Wikipedia](https://en.wikipedia.org/wiki/Foundation_models)
- [On The Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258)
- [What is Diffusion model?](https://www.youtube.com/watch?v=fbLgFrlTnGU)
- [High-Resolution Image Synthesis with Latent Diffusion Models](https://research.runwayml.com/publications/high-resolution-image-synthesis-with-latent-diffusion-models)
- [The research origins of Stable Diffusion](https://research.runwayml.com/the-research-origins-of-stable-difussion)
- [RunwayML.com](https://runwayml.com)
- [AI Magic Tools](https://app.runwayml.com/ai-tools)
- [Introductory Guide to ML Lab](https://help.runwayml.com/hc/en-us/categories/1500001962941-ML-Lab)
- [Introductory Guide to Video Editing](https://help.runwayml.com/hc/en-us/categories/1500001930562-Video-Editing)
- [Model Directory](https://app.runwayml.com/models)
- [RunwayML YouTube Channel](https://www.youtube.com/c/RunwayML)
- [Lexica: The Stable Diffusion search engine](https://lexica.art)
- [Image to Music demo](https://huggingface.co/spaces/fffiloni/img-to-music)
- [runwayml/stable-diffusion-v1-5 on Hugging face](https://huggingface.co/runwayml/stable-diffusion-v1-5)
- [Midjourney](https://www.midjourney.com/home)
- Where to find stock videos/image: [Pexel](https://www.pexels.com/)

## Related Projects

- [Projects Made with RunwayML](https://runwayml.com/madewith/)
- [AI Video editing workflow](https://twitter.com/paultrillo/status/1584543033449533441)

## Assignment (Due Friday, Nov 4):

#### Reading

- [The new era of foundation models, summarized](https://blog.agermanidis.com/foundation-models-summarized/)
- [The research origins of Stable Diffusion](https://research.runwayml.com/the-research-origins-of-stable-difussion)
- [Machine Learning En Plein Air: Building accessible tools for artists](https://medium.com/runwayml/machine-learning-en-plein-air-building-accessible-tools-for-artists-87bfc7f99f6b) by Cristóbal Valenzuela

#### Instructions

1. Pick one of the following tools to generate any media(image, video, text, 3D texuture). You can choose a workflow that you worked with in class or a different one. Feel free to try more than one if you like.

   - Runway: [AI Magic Tools](https://app.runwayml.com/ai-tools), [Models Playground](https://app.runwayml.com/models), [Video Editor](https://app.runwayml.com)
   - DALL-E: https://labs.openai.com

   Consider the following questions:

   - Describe the results of working with the tool, do they match your expectations?
   - Can you "break" the tool? In other words, use it in a way that it was intended for and what kinds of results do you get?
   - Can you find any pro tips in terms of prompt engineering? Can you change your prompt to make the generated results better?
   - You can also pick one image from [lexica](https://lexica.art) as a start point.

2. Document your thoughts on the above questions and your experience working with Runway/ DALL-E in a blog post. Include screenshots and screen captures of your workflow. Compare and constrast working with Runway as a tool for machine learning as related to ml5.js, python, and any other tools explored this semester. [Link from the homework wiki](https://github.com/ml5js/Intro-ML-Arts-IMA-F22/wiki/Assignment-8).
